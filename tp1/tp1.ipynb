{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/aprendizaje-automatico-dc-uba-ar/material/blob/main/tp/01_aprendizaje_supervisado/tp01-enunciado.ipynb)\n",
    "\n",
    "# Trabajo Práctico -  Aprendizaje supervisado\n",
    "### Clasificación de expresiones genómicas\n",
    "\n",
    "<span style=\"color: red;\">**Fecha de entrega: 01 de Mayo del 2024 - hasta las 23:55hs.**\n",
    "\n",
    "<span style=\"color: red;\">**Fecha de entrega intermedia: 25 de Abril del 2024 - hasta las 23:55hs.**\n",
    "</span>\n",
    "\n",
    "## Introducción\n",
    "\n",
    "En el mundo actual, distintas disciplinas científicas empiezan, cada vez más, a interactuar con el fin de potenciar sus descubrimientos. En este caso dos grupos de investigación de [CONICET](https://www.conicet.gov.ar/) se embarcan en la combinación entre biología y informática para abordar la detección temprana y el pronóstico preciso de enfermedades como el cáncer. Este proyecto combina las tecnologías de secuenciación de nueva generación ([_NGS_](https://es.wikipedia.org/wiki/Secuenciaci%C3%B3n_paralela_masiva), por sus siglas en inglés) con la potencia de la inteligencia artificial. El enfoque se centra en un dataset único que abarca mediciones de [_ARN_](https://es.wikipedia.org/wiki/ARN_mensajero) de 200 [_genes_](https://es.wikipedia.org/wiki/Gen), recopiladas de pacientes con lesiones [_pre-tumorales_](https://en.wikipedia.org/wiki/Hyperplasia). Este conjunto de datos se convierte en una valiosa fuente de información para entender cómo las células en estado de hiperplasia pueden evolucionar hacia [_tumores malignos_](https://en.wikipedia.org/wiki/Neoplasm), una transformación que ha desconcertado a la ciencia durante décadas.\n",
    "\n",
    "La hiperplasia, es un fenómeno en el que las células experimentan un crecimiento anormal y descontrolado, es un punto de partida crucial en nuestro análisis. ¿Cómo y por qué algunas células que experimentan hiperplasia se convierten en células cancerosas, mientras que otras no? Esta pregunta es el corazón de nuestra investigación. Para responderla se realizo un estudio donde se obtuvieron muestras de distintos tipos de hiperplasias de pacientes con antecedentes familiares y lesiones pre tumorales. Este grupo de pacientes, o cohorte, fue monitoreado periodicamente durante los siguientes 5 años buscando indicios de neoplasias o nuevas hiperplasias más agresivas. Con las muestras obtenidas en este estudio se realizo un [_biobanco_](https://en.wikipedia.org/wiki/Biobank) con las mediciones que habitualmente se hacen en la construccion de este tipo de [_plataformas_](https://xena.ucsc.edu/). Cada muestra fue etiquetada como **_buen pronostico_**, si no hubo indicios de nuevas hiperplasias o similares; contrariamente se etiquetaron como de **_mal pronostico_** si hubo una recaida.\n",
    "\n",
    "Este trabajo se concentra en un panel de genes, especificamente en la expresion de 200 genes que se creen tienen un papel crucial en la transformacion tumoral y su etiqueta correspondiente.\n",
    "\n",
    "En concreto:\n",
    "\n",
    "Tendrán un archivo `.csv` en donde se almacenan:\n",
    "  - una matriz de datos `X` de $500$ filas en donde cada fila $x^{(i)}$ representa un vector de $200$ características de cada instancia. Es decir, $\\textbf{x}^{(i)} = x_1^{(i)}, \\dots, x_{200}^{(i)}$ con $i$ entre $1$ y $500$.\n",
    "  - una columna llamada `target` que representa un vector de $500$ posiciones con dos posibles valores: `True` (ó 1, es decir, tiene buen pronostico) y `False` (ó 0, tiene mal pronostico).\n",
    "\n",
    "Los datos están en esta [carpeta](https://github.com/aprendizaje-automatico-dc-uba-ar/material/tree/main/tp/01_aprendizaje_supervisado/datos).\n",
    "\n",
    "Por otra parte, tendrán disponibles un conjunto de instancias sin etiquetas, que utilizaremos para comprobar la calidad de sus resultados (ver Ejercicio 5). \n",
    "\n",
    "**Recomendamos fuertemente leer primero todo el enunciado del trabajo antes de empezar a trabajar sobre el problema propuesto.**\n",
    "\n",
    "---\n",
    "\n",
    "### Sobre el informe\n",
    "\n",
    "Para este trabajo deberán entregar, además del código de las pruebas y experimentos que realicen, un informe en el que deberan seleccionar, para cada apartado, sus resultados acompañado de un texto que explique, reflexione, justifique y conluya dicho contenido. \n",
    "\n",
    "Cada ejercicio indica el largo máximo del texto que se puede incluir. Los gráficos no están contados en dicho espacio. \n",
    "Cada gráfico incluido debe contar con:\n",
    "  \n",
    "  - nombres de los ejes,\n",
    "  - título,\n",
    "  - leyenda autocontenida,\n",
    "  - debe ser referenciado desde el texto, ya que su inclusión se da porque aporta a la discusión del trabajo.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1 \n",
    "\n",
    "### Separación de datos (máximo 2 carillas del informe)\n",
    "\n",
    "Contarán con una cantidad limitada de datos, por lo cual es importante tomar una buena decisión en el momento de empezar a utilizarlos. \n",
    "\n",
    "Evaluar y justificar cómo separarán sus datos para desarrollo y para evaluación. \n",
    "\n",
    "**Importante**: en este punto no está permitido dividir la base de datos utilizando la función `train_test_split` de sklearn. Deben decidir e implementar la separación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero cargamos los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos la proporción de datos que tienen target = 1 y de los que tienen target = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.686\n",
       "1    0.314\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"target\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elegimos separar los datos con la idea de stratified, es decir, separar los datos pero asegurarnos de que las clases queden balanceadas. Elegimos separar el 85% de los datos para desarrollo (425 datos) y el 15% de los datos (75 datos) para evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(round(df[\"target\"].value_counts()[0]*0.85))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementamos una función que nos separe según lo que queremos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_split(df,prop=0.85):\n",
    "    cant_0 = df[\"target\"].value_counts()[0]\n",
    "    cant_1 = df[\"target\"].value_counts()[1]\n",
    "    df_0_indices = df[df[\"target\"]==0].index.to_list() #me quedo con los indices de los que tienen target = 0\n",
    "    df_1_indices = df[df[\"target\"]==1].index.to_list() #me quedo con los indices de los que tienen target = 1\n",
    "\n",
    "    random.seed(4)\n",
    "    prop_df_0 = random.sample(df_0_indices,round(cant_0*prop)) #292\n",
    "    menos_prop_df_0 = [idx for idx in df_0_indices if idx not in prop_df_0] #51\n",
    "    prop_df_1 = random.sample(df_1_indices,round(cant_1*prop)) #133\n",
    "    menos_prop_df_1 = [idx for idx in df_1_indices if idx not in prop_df_1] #24\n",
    "\n",
    "    desarrollo_indices = prop_df_0+prop_df_1\n",
    "    evaluacion_indices = menos_prop_df_0+menos_prop_df_1\n",
    "\n",
    "    desarrollo = df.loc[desarrollo_indices]\n",
    "    evaluacion = df.loc[evaluacion_indices]\n",
    "    return desarrollo,evaluacion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corremos la función:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev, eval = stratified_split(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos la cantidad de datos que quedó en cada uno de los datasets, el de desarrollo y el de evaluación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425\n",
      "75\n"
     ]
    }
   ],
   "source": [
    "print(len(dev))\n",
    "print(len(eval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora veamos que se respeta la proporción original en cada uno de los datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proporción de datos del dataset de desarrollo: \n",
      " 0    0.687059\n",
      "1    0.312941\n",
      "Name: target, dtype: float64\n",
      "Proporción de datos del dataset de evaluación: \n",
      " 0    0.68\n",
      "1    0.32\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Proporción de datos del dataset de desarrollo: \\n\",dev[\"target\"].value_counts(normalize=True))\n",
    "print(\"Proporción de datos del dataset de evaluación: \\n\",eval[\"target\"].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos los datos de desarrollo y evaluación en un nuevo archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval.to_csv(\"evaluacion.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev.to_csv(\"desarrollo.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "\n",
    "\n",
    "### Construcción de modelos (máximo 2 carillas del informe)\n",
    "\n",
    "Para este punto, la tarea consiste en construir y evaluar modelos de tipo **árbol de decisión**. Además, obtener una **estimación realista de la performance** de los mismos.\n",
    "\n",
    "1. Entrenar un árbol de decisión con altura máxima 3 y el resto de los hiperparámetros en default.\n",
    "\n",
    "1. Estimar la performance del modelo utilizando _K-fold cross validation_ con `K=5`, con las métricas _Accuracy_, _Area Under the Precision-Recall Curve (AUPRC)_., _Area Under the Receiver Operating Characteristic Curve (AUCROC)_. \n",
    "\n",
    "   En esta oportunidad se va a pedir además de calcular las métricas para cada fold por separado y su promedio, que hagan el cálculo del score global (como vimos en clase), sólo para los folds de validación.\n",
    "   \n",
    "   Reportar el resultado en una tabla similar a:\n",
    "\n",
    "      <table>\n",
    "      <thead>\n",
    "      <tr>\n",
    "      <th align=\"center\">Permutación</th>\n",
    "      <th>Accuracy (training)</th>\n",
    "      <th>Accuracy (validación)</th>\n",
    "      <th>AUPRC (training)</th>\n",
    "      <th>AUPRC (validación)</th>\n",
    "      <th>AUC ROC (training)</th>\n",
    "      <th>AUC ROC (validación)</th>\n",
    "      </tr>\n",
    "      </thead>\n",
    "      <tbody>\n",
    "      <tr>\n",
    "      <td align=\"center\">1</td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "      <td align=\"center\">2</td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "      <td align=\"center\">3</td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "      <td align=\"center\">4</td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "      <td align=\"center\">5</td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "      <td align=\"center\">Promedios</td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      </tr>\n",
    "      <td align=\"center\">Global</td>\n",
    "      <td>(NO) </td>\n",
    "      <td></td>\n",
    "      <td>(NO) </td>\n",
    "      <td></td>\n",
    "      <td>(NO) </td>\n",
    "      <td></td>\n",
    "      </tr>\n",
    "      </tbody>\n",
    "      </table>    \n",
    "  \n",
    "   **Importante**: de acá en más sólamente utilizaremos el score promedio cuando hagamos _K-fold cross-validation_.\n",
    " \n",
    "1. Explorar las siguientes combinaciones de parámetros para  árboles de decisión (siguiendo con $k-fold$ con $k=5$) utilizando [ParameterGrid](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ParameterGrid.html) de _scikit learn_. No está permitido utilizar `GridSearchCV` en este ejercicio.\n",
    "\n",
    "   <table>\n",
    "   <thead>\n",
    "   <tr>\n",
    "   <th align=\"center\">Altura máxima</th>\n",
    "   <th align=\"center\">Criterio de corte</th>\n",
    "   <th>Accuracy (training)</th>\n",
    "   <th>Accuracy (validación)</th>\n",
    "   </tr>\n",
    "   </thead>\n",
    "   <tbody><tr>\n",
    "   <td align=\"center\">3</td>\n",
    "   <td align=\"center\">Gini</td>\n",
    "   <td></td>\n",
    "   <td></td>\n",
    "   </tr>\n",
    "   <tr>\n",
    "   <td align=\"center\">5</td>\n",
    "   <td align=\"center\">Gini</td>\n",
    "   <td></td>\n",
    "   <td></td>\n",
    "   </tr>\n",
    "   <tr>\n",
    "   <td align=\"center\">Infinito</td>\n",
    "   <td align=\"center\">Gini</td>\n",
    "   <td></td>\n",
    "   <td></td>\n",
    "   </tr>\n",
    "   <tr>\n",
    "   <td align=\"center\">3</td>\n",
    "   <td align=\"center\">Entropía</td>\n",
    "   <td></td>\n",
    "   <td></td>\n",
    "   </tr>\n",
    "   <tr>\n",
    "   <td align=\"center\">5</td>\n",
    "   <td align=\"center\">Entropía</td>\n",
    "   <td></td>\n",
    "   <td></td>\n",
    "   </tr>\n",
    "   <tr>\n",
    "   <td align=\"center\">Infinito</td>\n",
    "   <td align=\"center\">Entropía</td>\n",
    "   <td></td>\n",
    "   <td></td>\n",
    "   </tr>\n",
    "   </tbody></table>\n",
    "\n",
    "\n",
    "1. ¿Qué conclusiones se pueden sacar de estas tablas?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Entrenar un árbol de decisión con altura máxima 3 y el resto de los hiperparámetros en default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos los datos de desarollo en train y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"desarrollo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(\n",
    "                    data[data.columns.difference(['target'])],\n",
    "                    data['target'],\n",
    "                    random_state=4,\n",
    "                    test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "arbol = DecisionTreeClassifier(max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arbol.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7905759162303665\n",
      "0.5813953488372093\n"
     ]
    }
   ],
   "source": [
    "print(arbol.score(x_train, y_train))\n",
    "print(arbol.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Estimar la performance del modelo utilizando _K-fold cross validation_ con `K=5`, con las métricas _Accuracy_, _Area Under the Precision-Recall Curve (AUPRC)_., _Area Under the Receiver Operating Characteristic Curve (AUCROC)_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, auc, precision_recall_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tree(X_tr: np.ndarray, y_tr: np.ndarray, tree_params={}) -> DecisionTreeClassifier:\n",
    "    arbol = DecisionTreeClassifier(**tree_params) #crea el arbol con ciertos hiperparametros que le pasas: la altura maxima \n",
    "    arbol.fit(X_tr, y_tr)\n",
    "\n",
    "    return arbol\n",
    "\n",
    "def tree_predict(ab: DecisionTreeClassifier, X_test: np.ndarray) -> np.ndarray:\n",
    "    predictions = ab.predict(X_test) #le pasas el arbol ya entrenado y te devuelve las predicciones del test\n",
    "    return predictions\n",
    "\n",
    "def metricas_seleccionadas(y_pred, y_real):\n",
    "    precision, recall, _ = precision_recall_curve(y_real,y_pred)\n",
    "    return accuracy_score(y_real, y_pred), auc(precision, recall), roc_auc_score(y_real, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#juntar x_train y x_test\n",
    "x = pd.concat([x_train, x_test])\n",
    "y = pd.concat([y_train, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.empty(y.shape) #creamos las predicciones globales\n",
    "y_pred.fill(np.nan)\n",
    "accuracy_folds_train = np.array([])\n",
    "aupcr_folds_train = np.array([])\n",
    "aucroc_folds_train = np.array([])\n",
    "accuracy_folds_test = np.array([])\n",
    "aupcr_folds_test = np.array([])\n",
    "aucroc_folds_test = np.array([])\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=4)\n",
    "\n",
    "for train_index, test_index in skf.split(x, y):\n",
    "    #en train_index estan los indices de los datos que estan en los 5 folds que pertenecen a training\n",
    "    #en test_index estan los indices de los datos que estan en el unico fold que es el test\n",
    "    \n",
    "    #saco el fold que no uso para entrenar\n",
    "    kf_X_train, kf_X_test = x.iloc[train_index], x.iloc[test_index]\n",
    "    kf_y_train, kf_y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    current_tree = train_tree(kf_X_train, kf_y_train,\n",
    "                                tree_params={\"max_depth\":3})\n",
    "    predictions_train = tree_predict(current_tree, kf_X_train)\n",
    "    predictions_test = tree_predict(current_tree, kf_X_test)\n",
    "    y_pred[test_index] = predictions_test #quedan algunos vacios (con NAs) en cada iteracion pero finalmente se llena todo\n",
    "    \n",
    "    accuracy_fold_train, aupcr_fold_train, aucroc_fold_train = metricas_seleccionadas(predictions_train, kf_y_train)\n",
    "    accuracy_fold_test, aupcr_fold_test, aucroc_fold_test = metricas_seleccionadas(predictions_test, kf_y_test)\n",
    "    \n",
    "    accuracy_folds_train = np.append(accuracy_folds_train, accuracy_fold_train)\n",
    "    accuracy_folds_test = np.append(accuracy_folds_test,accuracy_fold_test)\n",
    "    aupcr_folds_train = np.append(aupcr_folds_train, aupcr_fold_train)\n",
    "    aupcr_folds_test = np.append(aupcr_folds_test,aupcr_fold_test)\n",
    "    aucroc_folds_train = np.append(aucroc_folds_train, aucroc_fold_train) \n",
    "    aucroc_folds_test = np.append(aucroc_folds_test, aucroc_fold_test)\n",
    "\n",
    "accuracy_global, aupcr_global, aucroc_global = metricas_seleccionadas(y_pred, y) #mido que tan bien me fue con las predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crear un dataframe con las metricas\n",
    "df_metrics = pd.DataFrame({\n",
    "    \"fold\": np.arange(1,6),\n",
    "    \"accuracy_train\": accuracy_folds_train,\n",
    "    \"accuracy_test\": accuracy_folds_test,\n",
    "    \"aupcr_train\": aupcr_folds_train,\n",
    "    \"aupcr_test\": aupcr_folds_test,\n",
    "    \"aucroc_train\": aucroc_folds_train,\n",
    "    \"aucroc_test\": aucroc_folds_test\n",
    "})\n",
    "\n",
    "promedios = np.array([\"promedio\"])\n",
    "for column in df_metrics.columns[1:]:\n",
    "    promedio = df_metrics[column].mean()\n",
    "    promedios = np.append(promedios, round(promedio,6))\n",
    "\n",
    "\n",
    "df_metrics.loc[5] = promedios\n",
    "#agregar las metricas globales\n",
    "df_metrics.loc[6] = [\"global\", np.nan, accuracy_global, np.nan, aupcr_global, np.nan, aucroc_global]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>aupcr_train</th>\n",
       "      <th>aupcr_test</th>\n",
       "      <th>aucroc_train</th>\n",
       "      <th>aucroc_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.682353</td>\n",
       "      <td>0.460067</td>\n",
       "      <td>0.24724</td>\n",
       "      <td>0.78633</td>\n",
       "      <td>0.6206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>0.460067</td>\n",
       "      <td>0.144322</td>\n",
       "      <td>0.78633</td>\n",
       "      <td>0.543677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.826471</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>0.446895</td>\n",
       "      <td>0.242079</td>\n",
       "      <td>0.775883</td>\n",
       "      <td>0.617497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.841176</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.469634</td>\n",
       "      <td>0.245316</td>\n",
       "      <td>0.786567</td>\n",
       "      <td>0.61622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.838235</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>0.349095</td>\n",
       "      <td>0.794751</td>\n",
       "      <td>0.711367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>promedio</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.691765</td>\n",
       "      <td>0.460324</td>\n",
       "      <td>0.24561</td>\n",
       "      <td>0.785972</td>\n",
       "      <td>0.621872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>global</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.691765</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.247725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.622155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fold accuracy_train accuracy_test aupcr_train aupcr_test aucroc_train  \\\n",
       "0         1       0.835294      0.682353    0.460067    0.24724      0.78633   \n",
       "1         2       0.835294      0.635294    0.460067   0.144322      0.78633   \n",
       "2         3       0.826471      0.694118    0.446895   0.242079     0.775883   \n",
       "3         4       0.841176      0.705882    0.469634   0.245316     0.786567   \n",
       "4         5       0.838235      0.741176    0.464955   0.349095     0.794751   \n",
       "5  promedio       0.835294      0.691765    0.460324    0.24561     0.785972   \n",
       "6    global            NaN      0.691765         NaN   0.247725          NaN   \n",
       "\n",
       "  aucroc_test  \n",
       "0      0.6206  \n",
       "1    0.543677  \n",
       "2    0.617497  \n",
       "3     0.61622  \n",
       "4    0.711367  \n",
       "5    0.621872  \n",
       "6    0.622155  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Explorar las siguientes combinaciones de parámetros para  árboles de decisión (siguiendo con $k-fold$ con $k=5$) utilizando [ParameterGrid](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ParameterGrid.html) de _scikit learn_. No está permitido utilizar `GridSearchCV` en este ejercicio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(params):\n",
    "    y_pred = np.empty(y.shape) #creamos las predicciones globales\n",
    "    y_pred.fill(np.nan)\n",
    "    accuracy_folds_train = np.array([])\n",
    "    accuracy_folds_test = np.array([])\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=4)\n",
    "\n",
    "    for train_index, test_index in skf.split(x, y):\n",
    "        #en train_index estan los indices de los datos que estan en los 5 folds que pertenecen a training\n",
    "        #en test_index estan los indices de los datos que estan en el unico fold que es el test\n",
    "        \n",
    "        #saco el fold que no uso para entrenar\n",
    "        kf_X_train, kf_X_test = x.iloc[train_index], x.iloc[test_index]\n",
    "        kf_y_train, kf_y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        current_tree = train_tree(kf_X_train, kf_y_train,\n",
    "                                    tree_params=params)\n",
    "        predictions_train = tree_predict(current_tree, kf_X_train)\n",
    "        predictions_test = tree_predict(current_tree, kf_X_test)\n",
    "        y_pred[test_index] = predictions_test #quedan algunos vacios (con NAs) en cada iteracion pero finalmente se llena todo\n",
    "        \n",
    "        accuracy_fold_train = accuracy_score(kf_y_train, predictions_train)\n",
    "        accuracy_fold_test = accuracy_score(kf_y_test, predictions_test)\n",
    "        \n",
    "        accuracy_folds_train = np.append(accuracy_folds_train, accuracy_fold_train)\n",
    "        accuracy_folds_test = np.append(accuracy_folds_test,accuracy_fold_test)\n",
    "    return np.mean(accuracy_folds_train), np.mean(accuracy_folds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "profundidades = [3,5,None]\n",
    "metricas = [\"gini\", \"entropy\"]\n",
    "\n",
    "def crear_grilla(profundidades, metricas):\n",
    "    parametros = {\n",
    "        'max_depth': profundidades,\n",
    "        'criterion': metricas\n",
    "    }\n",
    "    grilla = list(ParameterGrid(parametros))\n",
    "    return grilla\n",
    "\n",
    "grilla_parametros = crear_grilla(profundidades, metricas)\n",
    "\n",
    "\n",
    "# Crear un DataFrame para almacenar los resultados\n",
    "resultados = pd.DataFrame(columns=['Altura máxima', 'Criterio de corte', 'Accuracy (training)', 'Accuracy (validación)'])\n",
    "i = 1\n",
    "for params in grilla_parametros:\n",
    "    max_depth = params['max_depth']\n",
    "    criterion = params['criterion']\n",
    "    accuracy_train, accuracy_val = grid_search(params)\n",
    "    resultados.loc[i, 'Altura máxima'] = str(max_depth) if max_depth is not None else 'Infinito'\n",
    "    resultados.loc[i, 'Criterio de corte'] = criterion.capitalize()\n",
    "    resultados.loc[i, 'Accuracy (training)'] = accuracy_train\n",
    "    resultados.loc[i, 'Accuracy (validación)'] = accuracy_val\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Altura máxima</th>\n",
       "      <th>Criterio de corte</th>\n",
       "      <th>Accuracy (training)</th>\n",
       "      <th>Accuracy (validación)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Gini</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.691765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Gini</td>\n",
       "      <td>0.938824</td>\n",
       "      <td>0.661176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Infinito</td>\n",
       "      <td>Gini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.635294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Entropy</td>\n",
       "      <td>0.805882</td>\n",
       "      <td>0.684706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Entropy</td>\n",
       "      <td>0.903529</td>\n",
       "      <td>0.677647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Infinito</td>\n",
       "      <td>Entropy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.696471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Altura máxima Criterio de corte Accuracy (training) Accuracy (validación)\n",
       "1             3              Gini            0.835294              0.691765\n",
       "2             5              Gini            0.938824              0.661176\n",
       "3      Infinito              Gini                 1.0              0.635294\n",
       "4             3           Entropy            0.805882              0.684706\n",
       "5             5           Entropy            0.903529              0.677647\n",
       "6      Infinito           Entropy                 1.0              0.696471"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. ¿Qué conclusiones se pueden sacar de estas tablas? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observaciones de la primera tabla:\n",
    "Primero, es importante decir que para las tres métricas siempre dió mejor en el set de training que en el de test. Esto se debe a que al modelo le resulta más fácil predecir datos que usó para entrenarse.\n",
    "* El accuracy global y el promedio dieron iguales.\n",
    "* El auroc y el aupcr globales y promedios también dieron muy similares, pero con una leve mejora en el global.\n",
    "* El aupcr para training para todos los folds dió siempre debajo de 0.35, es decir, muy mal. Lo mismo para aupcr test, dieron todos muy cercanos a 0.46. Esto nos da el indicio de que en general no logramos que tanto precision como recall sean altos al mismo tiempo, pero como estamos en el caso particular de clasificar tumores malignos de benignos, nos interesa especialmente minimizar los falsos positivos (clasificar como benigno cuando en realidad era maligno), es decir maximizar precision. Sería conveniente ver los gráficos.\n",
    "* El auroc para training dió muy parecido para todos los folds, al rededor de 0.78. Sin embargo, para test podemos ver que hay bastante variabilidad, el mayor tiene 0.711367 y el menor 0.543677. Vemos que nos dió mucho mejor que la aupcr. Como tenemos un dataset desbalanceado, el auroc es mejor métrica al momento de elegir un modelo.\n",
    "\n",
    "Precision: de las instancias predichas como positivas, ¿qué porcentaje eran positivas?: TP/(TP+FP)\n",
    "Recall: De las instancias positivas, ¿qué porcentaje fueron predichas como tal?: TP/(TP+FN)\n",
    "\n",
    "Observaciones de la segunda tabla:\n",
    "* Podemos ver que en la segunda tabla, cuando hacemos altura = 3 y criterio de corte = 'gini' los valores son de accuracy son iguales que accuracy promedio en la primera tabla (tanto para training como para evaluación), lo cual tiene sentido porque usamos la misma semilla y entonces los folds son los mismos. Además, porque en la primera tabla entrenamos un árbol de altura máxima = 3 y el paramétro por default de criterio es 'gini'.\n",
    "* Vemos que a medida que aumentamos la altura máxima de los árboles, aumenta el accuracy en el set de training para ambos criterios. Esto se debe a que mientras mayor altura, más se ajusta el modelo a los datos training.\n",
    "* Se puede observar que el accuracy de validación dió muy parecido para los distintos modelos, a diferencia del de training. Sin embargo, vemos que a diferencia del accuracy de training, no aumenta a medida que aumentamos la altura máxima del árbol. Esto se puede deber a que aumentar la altura del árbol no me ayuda a explicar la relación entre las instancias y la etiqueta, sino que lo que está pasando es que se está ajustando a los datos observados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "\n",
    "### Comparación de algoritmos \n",
    "\n",
    "Se pide explorar distintas combinaciones de algoritmos de aprendizaje con diferentes configuraciones con el objetivo de encontrar el mejor modelo de cada familia de buscar la performance óptima. Para este ejercicio realizar una experimentación utilizando [`RandomizedSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html). Como métrica de performance usar AUCROC resultante de 5-fold cross-validation. \n",
    "\n",
    "Algoritmos a probar: \n",
    "  - Árboles de decisión\n",
    "  - KNN (k-vecinos más cercanos)\n",
    "  - SVM (Support vector machine)\n",
    "  - LDA (Linear discriminant analysis)\n",
    "  - Naïve Bayes\n",
    "  \n",
    "_Hiperparámetros_: Revisar la documentación de cada uno para la búsqueda de combinaciones prometedoras. \n",
    "\n",
    "Documentación extra sobre [`Tuning hyper-parameters`](https://scikit-learn.org/stable/modules/grid_search.html), leer hasta 3.2.2.\n",
    "\n",
    "Para este ejercicio se pide generar un reporte que contenga: \n",
    "\n",
    "1. Una descripción de las distintas combinaciones consideradas y su performance asociada (las que consideren relevantes, con al menos la mejor combinación para cada algoritmo). \n",
    "\n",
    "1. Una breve explicación de los factores que creen que produjeron dicho resultado. \n",
    "\n",
    "Para cada método pueden incluir hasta media carilla de texto y los gráficos que considere relevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from scipy.stats import uniform, randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arbol\n",
    "arbol = DecisionTreeClassifier()\n",
    "dic_arbol = {\n",
    "    'max_depth': randint(1, 10), #equivale a una uniforme pero para enteros\n",
    "    'criterion': ['gini', 'entropy', 'log_loss']\n",
    "}\n",
    "\n",
    "#knn\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "dic_knn = {\n",
    "    'n_neighbors': randint(1, 20), #numero de vecinos\n",
    "    'weights': ['uniform', 'distance'], #pesos: cuando hacen la votación pueden tener todos el mismo peso = uniforme, \n",
    "                                        #o tener pesos distintos en función de la distancia = distance\n",
    "    'p': [1, 2] #distancia de minkowski (como se mide la distancia) p = 1 = manhattan y p = 2 = ecuclidiana \n",
    "}\n",
    "\n",
    "#svm\n",
    "svm_classifier = svm.SVC()\n",
    "dic_svm = {\n",
    "    'C': uniform(0, 10), #el C restringe las instancias que pueden caer en el lado incorrecto\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], #el kernel con el que cambiamos la dimension\n",
    "                                                    #lineal\n",
    "                                                    #poly: abajo aclaramos el grado\n",
    "                                                    #rbf: radial (el de los circulos)\n",
    "                                                    #sigmoid \n",
    "    'degree': randint(2, 11) #aclara el grado del polinomico, sino lo ignora\n",
    "}\n",
    "\n",
    "\n",
    "#Vemos que el kernel RBF es el que mejor se comporta, entonces hacemos una busqueda mas fina, dejandole mas libertad a C\n",
    "dic_svm2 = {\n",
    "    'C': uniform(0, 20), #el C restringe las instancias que pueden caer en el lado incorrecto\n",
    "    'kernel': ['rbf'], #el kernel con el que cambiamos la dimension\n",
    "}\n",
    "\n",
    "#lda\n",
    "lda_classifier = LinearDiscriminantAnalysis() #no tiene parametros\n",
    "dic_lda = {\n",
    "    #'priors': np.array([[0.68,0.32],[0.32,0.68],[0.85,0.15],[0.5,0.5],[0.15,0.85],[0.7,0.3],[0.3,0.7]]) #probabilidades a priori   \n",
    "    #ver que onda los priors \n",
    "}\n",
    "\n",
    "#naive bayes\n",
    "naive_bayes_classifier = GaussianNB()\n",
    "dic_naive_bayes = { #no tiene hiperparametros\n",
    "    'var_smoothing': uniform(0.000001, 0.001) , #suaviza la matriz de covarianza\n",
    "    'priors': np.array([[0.68,0.32],[0.32,0.68],[0.85,0.15],[0.5,0.5],[0.15,0.85],[0.7,0.3],[0.3,0.7]]) #probabilidades a priori\n",
    "    }\n",
    "\n",
    "# np.array([[0.68,0.32],[0.8,0.2],[0.5,0.5],[0.2,0.8],[0.1,0.9],[0.9,0.1],[0.7,0.3],[0.3,0.7],[0.6,0.4],[0.4,0.6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomized_search(modelo, parametros,x,y, iter):\n",
    "    random_search = RandomizedSearchCV(estimator=modelo, param_distributions=parametros, n_iter=iter,\n",
    "                                    scoring='roc_auc', cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42), \n",
    "                                    verbose=0, random_state=41, n_jobs=-1)\n",
    "    return random_search.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llamemos a la función para cada modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "El mejor AUROC:\n",
      "0.8196874255904063\n",
      "\n",
      "Mejores Parámetros:\n",
      "{'priors': array([0.15, 0.85]), 'var_smoothing': 0.0007638307636120596}\n"
     ]
    }
   ],
   "source": [
    "random = randomized_search(naive_bayes_classifier, dic_naive_bayes, x, y, 5)\n",
    "#ver todos los parametros que probo\n",
    "print(\"\\nEl mejor AUROC:\")\n",
    "print(random.best_score_)\n",
    "print(\"\\nMejores Parámetros:\")\n",
    "print(random.best_params_)\n",
    "\n",
    "resultados = random.cv_results_\n",
    "    \n",
    "    # Convertir los resultados a un DataFrame de Pandas para análisis\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "#for i in range(0,len(df_resultados[\"params\"])):\n",
    "    #df_resultados.at[i, \"params\"] = {  \"kernel\": df_resultados.loc[i, \"params\"][\"kernel\"] ,\n",
    "                                    #\"C\": round(df_resultados.loc[i, \"params\"][\"C\"],3) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'priors': [0.68, 0.32], 'var_smoothing': 0.00...</td>\n",
       "      <td>0.818144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'priors': [0.85, 0.15], 'var_smoothing': 0.00...</td>\n",
       "      <td>0.818144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'priors': [0.5, 0.5], 'var_smoothing': 0.0006...</td>\n",
       "      <td>0.816473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'priors': [0.7, 0.3], 'var_smoothing': 0.0006...</td>\n",
       "      <td>0.816473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'priors': [0.15, 0.85], 'var_smoothing': 0.00...</td>\n",
       "      <td>0.819687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params  mean_test_score\n",
       "0  {'priors': [0.68, 0.32], 'var_smoothing': 0.00...         0.818144\n",
       "1  {'priors': [0.85, 0.15], 'var_smoothing': 0.00...         0.818144\n",
       "2  {'priors': [0.5, 0.5], 'var_smoothing': 0.0006...         0.816473\n",
       "3  {'priors': [0.7, 0.3], 'var_smoothing': 0.0006...         0.816473\n",
       "4  {'priors': [0.15, 0.85], 'var_smoothing': 0.00...         0.819687"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_resultados[['params', 'mean_test_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mili\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "10 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Mili\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Mili\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\Mili\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 352, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Mili\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.61496642 0.63629623 0.62425665 0.58860948 0.58917379        nan\n",
      " 0.60217247        nan 0.57200176 0.58237023]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "modelos = [arbol, knn_classifier, svm_classifier, svm_classifier, lda_classifier, naive_bayes_classifier]\n",
    "dic = [dic_arbol, dic_knn, dic_svm, dic_svm2, dic_lda, dic_naive_bayes]\n",
    "cantidad_iteraciones = [10, 10, 10, 10, 1, 10]\n",
    "\n",
    "top5 = pd.DataFrame(columns=[\"Modelo\", \"mean_AUROC\", \"parametros\"])\n",
    "\n",
    "for i in range(0,6):\n",
    "    resultados = randomized_search(modelos[i], dic[i], x, y, cantidad_iteraciones[i])\n",
    "    parametros_probados = pd.DataFrame(resultados.cv_results_)\n",
    "    parametros_probados = parametros_probados[['params', 'mean_test_score']]\n",
    "    parametros_ordenados = parametros_probados.sort_values(by='mean_test_score', ascending=False)\n",
    "    parametros_seleccionados = parametros_ordenados.head(5).copy()  # Crear una copia del DataFrame\n",
    "    \n",
    "    parametros_seleccionados[\"Modelo\"] = str(modelos[i])\n",
    "    parametros_seleccionados = parametros_seleccionados.rename(columns={\"mean_test_score\": \"mean_AUROC\", \"params\": \"parametros\"})\n",
    "\n",
    "    top5 = pd.concat([top5, parametros_seleccionados], ignore_index=True)  # Usar ignore_index=True para reindexar el DataFrame resultante\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>mean_AUROC</th>\n",
       "      <th>parametros</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.636296</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.624257</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.614966</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 4}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.602172</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.589174</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 9}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.839378</td>\n",
       "      <td>{'n_neighbors': 7, 'p': 1, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.82862</td>\n",
       "      <td>{'n_neighbors': 14, 'p': 1, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.826467</td>\n",
       "      <td>{'n_neighbors': 12, 'p': 1, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.794974</td>\n",
       "      <td>{'n_neighbors': 3, 'p': 1, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.793982</td>\n",
       "      <td>{'n_neighbors': 18, 'p': 2, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.891078</td>\n",
       "      <td>{'C': 7.239741430299464, 'degree': 4, 'kernel'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.858611</td>\n",
       "      <td>{'C': 0.6952046781160548, 'degree': 7, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.828771</td>\n",
       "      <td>{'C': 3.1467693397954024, 'degree': 7, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.80011</td>\n",
       "      <td>{'C': 6.038656889488131, 'degree': 10, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.797364</td>\n",
       "      <td>{'C': 6.968781524681335, 'degree': 6, 'kernel'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.892637</td>\n",
       "      <td>{'C': 5.018472474898803, 'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.89124</td>\n",
       "      <td>{'C': 3.8186132555947827, 'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.891211</td>\n",
       "      <td>{'C': 8.375601738986058, 'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.891078</td>\n",
       "      <td>{'C': 13.536324822211167, 'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.891078</td>\n",
       "      <td>{'C': 12.077313778976261, 'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LinearDiscriminantAnalysis()</td>\n",
       "      <td>0.753419</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>0.822782</td>\n",
       "      <td>{'priors': [0.5, 0.5], 'var_smoothing': 0.0009...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>0.820462</td>\n",
       "      <td>{'priors': [0.68, 0.32], 'var_smoothing': 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>0.819687</td>\n",
       "      <td>{'priors': [0.15, 0.85], 'var_smoothing': 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>0.818144</td>\n",
       "      <td>{'priors': [0.85, 0.15], 'var_smoothing': 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>0.818144</td>\n",
       "      <td>{'priors': [0.15, 0.85], 'var_smoothing': 0.00...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Modelo mean_AUROC  \\\n",
       "0       DecisionTreeClassifier()   0.636296   \n",
       "1       DecisionTreeClassifier()   0.624257   \n",
       "2       DecisionTreeClassifier()   0.614966   \n",
       "3       DecisionTreeClassifier()   0.602172   \n",
       "4       DecisionTreeClassifier()   0.589174   \n",
       "5         KNeighborsClassifier()   0.839378   \n",
       "6         KNeighborsClassifier()    0.82862   \n",
       "7         KNeighborsClassifier()   0.826467   \n",
       "8         KNeighborsClassifier()   0.794974   \n",
       "9         KNeighborsClassifier()   0.793982   \n",
       "10                         SVC()   0.891078   \n",
       "11                         SVC()   0.858611   \n",
       "12                         SVC()   0.828771   \n",
       "13                         SVC()    0.80011   \n",
       "14                         SVC()   0.797364   \n",
       "15                         SVC()   0.892637   \n",
       "16                         SVC()    0.89124   \n",
       "17                         SVC()   0.891211   \n",
       "18                         SVC()   0.891078   \n",
       "19                         SVC()   0.891078   \n",
       "20  LinearDiscriminantAnalysis()   0.753419   \n",
       "21                  GaussianNB()   0.822782   \n",
       "22                  GaussianNB()   0.820462   \n",
       "23                  GaussianNB()   0.819687   \n",
       "24                  GaussianNB()   0.818144   \n",
       "25                  GaussianNB()   0.818144   \n",
       "\n",
       "                                           parametros  \n",
       "0               {'criterion': 'gini', 'max_depth': 3}  \n",
       "1               {'criterion': 'gini', 'max_depth': 2}  \n",
       "2               {'criterion': 'gini', 'max_depth': 4}  \n",
       "3               {'criterion': 'gini', 'max_depth': 5}  \n",
       "4            {'criterion': 'entropy', 'max_depth': 9}  \n",
       "5    {'n_neighbors': 7, 'p': 1, 'weights': 'uniform'}  \n",
       "6   {'n_neighbors': 14, 'p': 1, 'weights': 'uniform'}  \n",
       "7   {'n_neighbors': 12, 'p': 1, 'weights': 'uniform'}  \n",
       "8   {'n_neighbors': 3, 'p': 1, 'weights': 'distance'}  \n",
       "9   {'n_neighbors': 18, 'p': 2, 'weights': 'uniform'}  \n",
       "10  {'C': 7.239741430299464, 'degree': 4, 'kernel'...  \n",
       "11  {'C': 0.6952046781160548, 'degree': 7, 'kernel...  \n",
       "12  {'C': 3.1467693397954024, 'degree': 7, 'kernel...  \n",
       "13  {'C': 6.038656889488131, 'degree': 10, 'kernel...  \n",
       "14  {'C': 6.968781524681335, 'degree': 6, 'kernel'...  \n",
       "15          {'C': 5.018472474898803, 'kernel': 'rbf'}  \n",
       "16         {'C': 3.8186132555947827, 'kernel': 'rbf'}  \n",
       "17          {'C': 8.375601738986058, 'kernel': 'rbf'}  \n",
       "18         {'C': 13.536324822211167, 'kernel': 'rbf'}  \n",
       "19         {'C': 12.077313778976261, 'kernel': 'rbf'}  \n",
       "20                                                 {}  \n",
       "21  {'priors': [0.5, 0.5], 'var_smoothing': 0.0009...  \n",
       "22  {'priors': [0.68, 0.32], 'var_smoothing': 0.00...  \n",
       "23  {'priors': [0.15, 0.85], 'var_smoothing': 0.00...  \n",
       "24  {'priors': [0.85, 0.15], 'var_smoothing': 0.00...  \n",
       "25  {'priors': [0.15, 0.85], 'var_smoothing': 0.00...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>mean_AUROC</th>\n",
       "      <th>parametros</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.892637</td>\n",
       "      <td>{'C': 5.018472474898803, 'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.89124</td>\n",
       "      <td>{'C': 3.8186132555947827, 'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.891211</td>\n",
       "      <td>{'C': 8.375601738986058, 'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.891078</td>\n",
       "      <td>{'C': 12.077313778976261, 'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.891078</td>\n",
       "      <td>{'C': 7.239741430299464, 'degree': 4, 'kernel'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.891078</td>\n",
       "      <td>{'C': 13.536324822211167, 'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.858611</td>\n",
       "      <td>{'C': 0.6952046781160548, 'degree': 7, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.839378</td>\n",
       "      <td>{'n_neighbors': 7, 'p': 1, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.828771</td>\n",
       "      <td>{'C': 3.1467693397954024, 'degree': 7, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.82862</td>\n",
       "      <td>{'n_neighbors': 14, 'p': 1, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.826467</td>\n",
       "      <td>{'n_neighbors': 12, 'p': 1, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>0.822651</td>\n",
       "      <td>{'priors': [0.5, 0.5], 'var_smoothing': 0.0009...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>0.820462</td>\n",
       "      <td>{'priors': [0.68, 0.32], 'var_smoothing': 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>0.819687</td>\n",
       "      <td>{'priors': [0.15, 0.85], 'var_smoothing': 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>0.818144</td>\n",
       "      <td>{'priors': [0.85, 0.15], 'var_smoothing': 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>0.818144</td>\n",
       "      <td>{'priors': [0.68, 0.32], 'var_smoothing': 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.80011</td>\n",
       "      <td>{'C': 6.038656889488131, 'degree': 10, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.797364</td>\n",
       "      <td>{'C': 6.968781524681335, 'degree': 6, 'kernel'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.794974</td>\n",
       "      <td>{'n_neighbors': 3, 'p': 1, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.793982</td>\n",
       "      <td>{'n_neighbors': 18, 'p': 2, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LinearDiscriminantAnalysis()</td>\n",
       "      <td>0.753419</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.630156</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.624257</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.610313</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.594721</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.594152</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 4}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Modelo mean_AUROC  \\\n",
       "15                         SVC()   0.892637   \n",
       "16                         SVC()    0.89124   \n",
       "17                         SVC()   0.891211   \n",
       "19                         SVC()   0.891078   \n",
       "10                         SVC()   0.891078   \n",
       "18                         SVC()   0.891078   \n",
       "11                         SVC()   0.858611   \n",
       "5         KNeighborsClassifier()   0.839378   \n",
       "12                         SVC()   0.828771   \n",
       "6         KNeighborsClassifier()    0.82862   \n",
       "7         KNeighborsClassifier()   0.826467   \n",
       "21                  GaussianNB()   0.822651   \n",
       "22                  GaussianNB()   0.820462   \n",
       "23                  GaussianNB()   0.819687   \n",
       "25                  GaussianNB()   0.818144   \n",
       "24                  GaussianNB()   0.818144   \n",
       "13                         SVC()    0.80011   \n",
       "14                         SVC()   0.797364   \n",
       "8         KNeighborsClassifier()   0.794974   \n",
       "9         KNeighborsClassifier()   0.793982   \n",
       "20  LinearDiscriminantAnalysis()   0.753419   \n",
       "0       DecisionTreeClassifier()   0.630156   \n",
       "1       DecisionTreeClassifier()   0.624257   \n",
       "2       DecisionTreeClassifier()   0.610313   \n",
       "3       DecisionTreeClassifier()   0.594721   \n",
       "4       DecisionTreeClassifier()   0.594152   \n",
       "\n",
       "                                           parametros  \n",
       "15          {'C': 5.018472474898803, 'kernel': 'rbf'}  \n",
       "16         {'C': 3.8186132555947827, 'kernel': 'rbf'}  \n",
       "17          {'C': 8.375601738986058, 'kernel': 'rbf'}  \n",
       "19         {'C': 12.077313778976261, 'kernel': 'rbf'}  \n",
       "10  {'C': 7.239741430299464, 'degree': 4, 'kernel'...  \n",
       "18         {'C': 13.536324822211167, 'kernel': 'rbf'}  \n",
       "11  {'C': 0.6952046781160548, 'degree': 7, 'kernel...  \n",
       "5    {'n_neighbors': 7, 'p': 1, 'weights': 'uniform'}  \n",
       "12  {'C': 3.1467693397954024, 'degree': 7, 'kernel...  \n",
       "6   {'n_neighbors': 14, 'p': 1, 'weights': 'uniform'}  \n",
       "7   {'n_neighbors': 12, 'p': 1, 'weights': 'uniform'}  \n",
       "21  {'priors': [0.5, 0.5], 'var_smoothing': 0.0009...  \n",
       "22  {'priors': [0.68, 0.32], 'var_smoothing': 0.00...  \n",
       "23  {'priors': [0.15, 0.85], 'var_smoothing': 0.00...  \n",
       "25  {'priors': [0.85, 0.15], 'var_smoothing': 0.00...  \n",
       "24  {'priors': [0.68, 0.32], 'var_smoothing': 0.00...  \n",
       "13  {'C': 6.038656889488131, 'degree': 10, 'kernel...  \n",
       "14  {'C': 6.968781524681335, 'degree': 6, 'kernel'...  \n",
       "8   {'n_neighbors': 3, 'p': 1, 'weights': 'distance'}  \n",
       "9   {'n_neighbors': 18, 'p': 2, 'weights': 'uniform'}  \n",
       "20                                                 {}  \n",
       "0               {'criterion': 'gini', 'max_depth': 3}  \n",
       "1               {'criterion': 'gini', 'max_depth': 2}  \n",
       "2               {'criterion': 'gini', 'max_depth': 5}  \n",
       "3            {'criterion': 'entropy', 'max_depth': 8}  \n",
       "4               {'criterion': 'gini', 'max_depth': 4}  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top5.sort_values(by='mean_AUROC', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4: \n",
    "### Diagnóstico Sesgo-Varianza.\n",
    "\n",
    "<span style=\"color: red;\">(no realizar hasta la clase _Sesgo y Varianza_)</span>\n",
    "\n",
    "En este punto, se pide inspeccionar **tres** de sus mejores modelos encontrados hasta ahora de cada familia de modelos: la mejor configuración para el árbol de decisión, la mejor configuración para LDA y la mejor configuración para SVM. Para ello:\n",
    "\n",
    "1. Graficar curvas de complejidad para cada modelo (excepto para LDA), variando la profundidad en el caso de árboles, y el hiperparámetro C en el caso de SVM. Diagnosticar cómo afectan al sesgo y a la varianza esos dos hiperparámetros.\n",
    "2. Graficar curvas de aprendizaje para cada modelo. En base a estas curvas, sacar conclusiones sobre si los algoritmos parecen haber alcanzado su límite, o bien si aumentar la cantidad de datos debería ayudar.\n",
    "3. Construir un modelo **RandomForest** con 200 árboles. Explorar para qué sirve el hiperparámetro max_features y cómo afecta a la performance del algoritmo mediante una curva de complejidad. Explicar por qué creen que se dieron los resultados obtenidos. Por último, graficar una curva de aprendizaje sobre los parámetros elegidos para determinar si sería útil o no conseguir más datos.\n",
    "\n",
    "\n",
    "**Atención**: Tener en cuenta que debemos seguir utilizando AUC ROC como métrica para estas curvas.\n",
    "\n",
    "Para cada método pueden incluir hasta una carilla de texto y los gráficos que considere relevantes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Graficar curvas de complejidad para cada modelo (excepto para LDA), variando la profundidad en el caso de árboles, y el hiperparámetro C en el caso de SVM. Diagnosticar cómo afectan al sesgo y a la varianza esos dos hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejor_modelo_arbol = top5[0:1]\n",
    "mejor_modelo_svm = top5[15:16] \n",
    "mejor_modelo_lda = top5[20:21] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>mean_AUROC</th>\n",
       "      <th>parametros</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.892637</td>\n",
       "      <td>{'C': 5.018472474898803, 'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Modelo mean_AUROC                                 parametros\n",
       "15  SVC()   0.892637  {'C': 5.018472474898803, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mejor_modelo_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>mean_AUROC</th>\n",
       "      <th>parametros</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.636296</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 3}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Modelo mean_AUROC                             parametros\n",
       "0  DecisionTreeClassifier()   0.636296  {'criterion': 'gini', 'max_depth': 3}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mejor_modelo_arbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "max_depth_values = range(1, 20)\n",
    "\n",
    "# Inicializar listas para almacenar las puntuaciones de entrenamiento y prueba\n",
    "train_auroc = []\n",
    "test_auroc = []\n",
    "\n",
    "# Calcular puntuaciones para cada valor de profundidad máxima\n",
    "for max_depth in max_depth_values:\n",
    "    auroc_promedio_train, auroc_promedio_test = auroc_complejidad(DecisionTreeClassifier, params={\"max_depth\": max_depth, \"criterion\": \"gini\"})\n",
    "    train_auroc.append(1-auroc_promedio_train)\n",
    "    test_auroc.append(1-auroc_promedio_test)\n",
    "\n",
    "\n",
    "# Graficar las curvas de complejidad\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(max_depth_values, train_auroc, label='Error de entrenamiento', marker='o')\n",
    "plt.plot(max_depth_values, test_auroc, label='Error de test', marker='o')\n",
    "plt.xticks(range(1, 21))\n",
    "plt.xlabel('Profundidad máxima del árbol')\n",
    "plt.ylabel('Error de AUROC')\n",
    "plt.title('Curva de complejidad para árbol de decisión')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que la curva de test dió con mucho error en todas las alturas. En la que menos dió es en max_depth = 3, que es la altura máxima del mejor modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auroc_complejidad(modelo, params):\n",
    "    y_pred = np.empty(y.shape) #creamos las predicciones globales\n",
    "    y_pred.fill(np.nan)\n",
    "    auroc_folds_train = np.array([])\n",
    "    auroc_folds_test = np.array([])\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=4)\n",
    "\n",
    "    for train_index, test_index in skf.split(x, y):\n",
    "        #en train_index estan los indices de los datos que estan en los 5 folds que pertenecen a training\n",
    "        #en test_index estan los indices de los datos que estan en el unico fold que es el test\n",
    "        \n",
    "        #saco el fold que no uso para entrenar\n",
    "        kf_X_train, kf_X_test = x.iloc[train_index], x.iloc[test_index]\n",
    "        kf_y_train, kf_y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        current_model = modelo(**params)\n",
    "        current_model.fit(kf_X_train, kf_y_train)\n",
    "        predictions_train = current_model.predict(kf_X_train)\n",
    "        predictions_test = current_model.predict(kf_X_test)\n",
    "\n",
    "        auroc_fold_train = roc_auc_score(kf_y_train, predictions_train)\n",
    "        auroc_fold_test = roc_auc_score(kf_y_test, predictions_test)\n",
    "        \n",
    "        auroc_folds_train = np.append(auroc_folds_train, auroc_fold_train)\n",
    "        auroc_folds_test = np.append(auroc_folds_test,auroc_fold_test)\n",
    "        \n",
    "    return np.mean(auroc_folds_train), np.mean(auroc_folds_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5: \n",
    "### Evaluación de performance\n",
    "\n",
    "- La entrega del trabajo estará acompañada de una evaluación en la cual deberán poner a prueba su mejor modelo y sobre todo, su capacidad para estimar sus resultados. \n",
    "\n",
    "- Su tarea será estimar la performance (AUCROC) que tendrá su mejor modelo en datos de evaluación (X_held_out). \n",
    "\n",
    "- Para ello, deberán predecir las **probabilidades** de las distintas instancias con su modelo, enviarnos dichas probabilidades junto a una estimación con 4 decimales de cuál será el AUCROC resultante y calcularemos el resultado real. Consideraremos que el **mejor modelo será el que se encuentre más cerca del valor real que calcularemos luego de la entrega**.\n",
    "\n",
    "- Recomendamos no perder de vista esta evaluación/competencia durante el desarrollo del TP, sobretodo en el momento de separar los datos en los primeros puntos. \n",
    "\n",
    "- Para que podamos evaluar la performance, junto con la entrega del informe, deberán enviar un archivo con el numero de grupo con dos digitos en formato csv con la columna `output` y el valor obtenido con 4 decimales (se subirá un ejemplo cuando se publiquen los datos de la competencia) y un valor esperado de AUCROC: `GG_y_pred_held_out_AUCROC`. \n",
    "\n",
    "    - Ej.: el grupo tres cree que obtuvo un valor de 0.7321 de AUCROC deberá submitear un archivo llamado: `03_y_pred_held_out_7321.csv`.\n",
    "\n",
    "- Los datos podrán encontrarlos en este [link](https://github.com/aprendizaje-automatico-dc-uba-ar/material/tree/main/tp/01_aprendizaje_supervisado/datos).\n",
    "\n",
    "- Las decisiones de este punto pueden desarrollarse hasta en una carilla, aunque con media debería alcanzar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 6: \n",
    "### Conclusiones\n",
    "\n",
    "Dar en a lo sumo 2 carillas una conclusión del trabajo realizado, incluyendo problemas encontrados y \n",
    "dimensiones no incluidas en el enunciado que hayan sido abordadas durante el desarrollo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Entregables\n",
    "- Contarán con un esqueleto en formato Jupyter Notebook en donde podrán intercalar celdas para reportar y responder a los ítems de cada ejercicio. \n",
    "- Los entregrables serán\n",
    "    - Un informe en formato .pdf (**digital**) que responda a los ítems de este enunciado respetando la cantidad de espacio máximo por cada ítem. Nombrarlo siguiendo el formato `GG_Nombre_de_grupo`\n",
    "    - Adjuntar el notebook final en formatos .pdf e .ipynb. Es necesario que los resultados puedan reproducirse al ejecutar todas las celdas en orden (verificarlo haceindo: Kernel -> Restart and Run All). \n",
    "    - Las predicciones del *held out* del punto 5 en formato csv.\n",
    "- Habŕa una entrega intermedia obligatoria que deberán hacer antes del 25 de abril de 2024 a las 23:55hs. Para esta entrega deberán enviar el código que resuelve los primeros 3 ejercicios. \n",
    "- La **fecha** y **hora límite** de entrega está determinada en el campus de la materia.\n",
    "- El trabajo deberá elaborarse en grupos de hasta 4 personas (4 preferentemente).\n",
    "- Se podrán pedir pruebas de integridad y autoría; es decir, verificar que la salida solicitada es fruto del modelo presentado y que el modelo fue construido según lo requerido en este enunciado.\n",
    "- La evaluación será grupal y se basará en la calidad del informe (presentación, claridad, prolijidad); la originalidad, practicidad y coherencia técnica de la solución; la corrección y solidez de las pruebas realizadas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importante: sobre el uso de ChatGPT y grandes modelos de lenguaje\n",
    "\n",
    "En este trabajo no estará explícitamente prohibido pero si fuertemente desaconsejado, consideramos a este trabajo práctico una importante herramienta de aprendizaje donde el uso de GPT puede ser perjudicial. En caso de usarlo se pide aclararlo en el informe y especificar cómo y en donde se utilizó. Así como expresar su opinión sobre la respuesta generada por el modelo pudiendo estar a favor o en contra de lo propuesto por este. Pueden adjuntar el link a la conversación con el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota**: Agradecemos a [Martín García Sola](https://ar.linkedin.com/in/martin-e-garcia-sola) por la asistencia biológica en la confección de este Trabajo Práctico."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
