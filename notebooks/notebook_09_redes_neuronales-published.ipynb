{"cells":[{"cell_type":"markdown","metadata":{},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/aprendizaje-automatico-dc-uba-ar/material/blob/main/notebooks/notebook_09_redes_neuronales-published.ipynb)\n","\n","# Redes neuronales\n","\n","\n","Vamos nuevamente a trabajar con los datos de `iris` para entrenar (y antes construir) una Red Neuronal."]},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[],"source":["import sklearn"]},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[{"data":{"text/plain":["array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n","       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n","       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int64)"]},"execution_count":70,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.preprocessing import LabelEncoder #es para transformar las etiquetas en valores numéricos\n","from sklearn.datasets import load_iris\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","def get_data():\n","    dataset = load_iris()\n","    X = dataset[\"data\"]\n","    y = dataset[\"target\"] #estaba en formato string, del tipo de flor, que eran 3 tipos: setosa, versicolor, virginica\n","    y = LabelEncoder().fit_transform(y) #lo transforma a un valor numérico\n","    return np.array(X), np.array(y)\n","X, y = get_data()\n","X\n","y"]},{"cell_type":"markdown","metadata":{},"source":["La propuesta es empezar por el esqueleto de las 2 clases que usaremos para esta tarea e ir implementado los métodos a medida que avancemos.\n","\n","Al final de este notebook se encuentran ambas clases completas. Pueden copiar el código desde allí mismo o implementarlo. La idea es que en cada avance podamos comprender la parte del proceso que estamos realizando, por lo cual se recomienda seguir la guia propuesta e ir completando sólo lo que es necesario para cada punto."]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[],"source":["class Capa:\n","    def __init__(self, neuronas):\n","        self.neuronas = neuronas\n","\n","    def forward(self, inputs, weights, bias, activation):\n","        \"\"\"\n","        Forward Propagation de la capa\n","        \"\"\"\n","        Z_curr = np.dot(inputs, weights.T) + bias #Z = XW + b\n","\n","        if activation == 'relu':\n","            A_curr = self.relu(inputs=Z_curr) #A = ReLU(Z)\n","        elif activation == 'softmax':\n","            A_curr = self.softmax(inputs=Z_curr) #A = Softmax(Z)\n","\n","        return A_curr, Z_curr\n","        \n","    def relu(self, inputs):\n","        \"\"\"\n","        ReLU: función de activación\n","        \"\"\"\n","\n","        return np.maximum(0, inputs)\n","\n","    def softmax(self, inputs):\n","        \"\"\"\n","        Softmax: función de activación\n","        \"\"\"\n","        exp_scores = np.exp(inputs)\n","        probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n","        return probs\n","    \n","    def backward(self, dA_curr, W_curr, Z_curr, A_prev, activation):\n","        \"\"\"\n","        Backward Propagation de la capa\n","        \"\"\"\n","        if activation == 'softmax':\n","            dW = np.dot(A_prev.T, dA_curr)\n","            db = np.sum(dA_curr, axis=0, keepdims=True)\n","            dA = np.dot(dA_curr, W_curr) \n","        else:\n","            dZ = self.relu_derivative(dA_curr, Z_curr)\n","            dW = np.dot(A_prev.T, dZ)\n","            db = np.sum(dZ, axis=0, keepdims=True)\n","            dA = np.dot(dZ, W_curr)\n","            \n","        return dA, dW, db\n","\n","    def relu_derivative(self, dA, Z):\n","        \"\"\"\n","        ReLU: gradiente de ReLU\n","        \"\"\"\n","        dZ = np.array(dA, copy = True) #copia el vector\n","        dZ[Z <= 0] = 0 #a los negativos les asigna 0\n","        dZ[Z > 0] = 1 #a los positivos les asigna 1\n","        return dZ"]},{"cell_type":"code","execution_count":99,"metadata":{},"outputs":[],"source":["class RedNeuronal:\n","    def __init__(self, learning_rate=0.01):\n","        self.red = [] ## capas\n","        self.arquitectura = [] ## mapeo de entradas -> salidas\n","        self.pesos = [] ## W, b\n","        self.memoria = [] ## Z, A\n","        self.gradientes = [] ## dW, db\n","        self.lr = learning_rate\n","        \n","    def add(self, capa):\n","        \"\"\"\n","        Agregar capa a la red\n","        \"\"\"\n","        self.red.append(capa) #agregamos una capa a la red\n","            \n","    def _compile(self, data):\n","        \"\"\"\n","        Inicializar la arquitectura\n","        \"\"\"\n","        for idx, _ in enumerate(self.red):\n","            if idx == 0:\n","                self.arquitectura.append({'input_dim': data.shape[1], \n","                                        'output_dim': self.red[idx].neuronas,\n","                                        'activation':'relu'})\n","            elif idx > 0 and idx < len(self.red)-1:\n","                self.arquitectura.append({'input_dim': self.red[idx-1].neuronas, \n","                                        'output_dim': self.red[idx].neuronas,\n","                                        'activation':'relu'})\n","            else:\n","                self.arquitectura.append({'input_dim': self.red[idx-1].neuronas, \n","                                        'output_dim': self.red[idx].neuronas,\n","                                        'activation':'softmax'})\n","    \n","    def _init_weights(self, data):\n","        \"\"\"\n","        Inicializar arquitectura y los pesos\n","        \"\"\"\n","        self._compile(data)\n","\n","        np.random.seed(99)\n","\n","        for i in range(len(self.arquitectura)):\n","            self.pesos.append({\n","                'W':np.random.uniform(low=-1, high=1, \n","                        size=(self.arquitectura[i]['input_dim'],\n","                            self.arquitectura[i]['output_dim']\n","                            )),\n","                'b':np.zeros((1, self.arquitectura[i]['output_dim']))})\n","\n","        return self\n","    \n","    def _forwardprop(self, data):\n","        \"\"\"\n","        Pasada forward completa por la red\n","        \"\"\"\n","        A_curr = data \n","\n","        for i in range(len(self.pesos)):\n","            A_prev = A_curr\n","            A_curr, Z_curr = self.red[i].forward(inputs=A_prev, \n","                                                    weights=self.pesos[i]['W'].T, \n","                                                    bias=self.pesos[i]['b'], \n","                                                    activation=self.arquitectura[i]['activation'])\n","\n","            self.memoria.append({'inputs':A_prev, 'Z':Z_curr})\n","\n","        return A_curr\n","    \n","    def _backprop(self, predicted, actual):\n","        \"\"\"\n","        Pasada backward completa por la red\n","        \"\"\"\n","        num_samples = len(actual)\n","\n","        ## compute the gradient on predictions\n","        dscores = predicted #softmax output\n","        dscores[range(num_samples),actual] -= 1 #derivada de la función de pérdida\n","        dscores /= num_samples #normalizar\n","\n","        dA_prev = dscores #dA de la última capa\n","\n","        for idx, layer in reversed(list(enumerate(self.red))):\n","            dA_curr = dA_prev\n","\n","            A_prev = self.memoria[idx]['inputs']\n","            Z_curr = self.memoria[idx]['Z']\n","            W_curr = self.pesos[idx]['W']\n","\n","            activation = self.arquitectura[idx]['activation']\n","\n","            dA_prev, dW_curr, db_curr = layer.backward(dA_curr, W_curr.T, Z_curr, A_prev, activation)\n","\n","            self.gradientes.append({'dW':dW_curr, 'db':db_curr})\n","\n","        self.gradientes = list(reversed(self.gradientes))  # Reverse the gradients list\n","            \n","    def _update(self):\n","        \"\"\"\n","        Actualizar el modelo --> lr * gradiente\n","        \"\"\"\n","        lr = self.lr\n","        for idx, layer in enumerate(self.red):\n","            self.pesos[idx]['W'] -= lr * self.gradientes[idx]['dW']\n","            self.pesos[idx]['b'] -= lr * self.gradientes[idx]['db']\n","\n","    def _get_accuracy(self, predicted, actual):\n","        \"\"\"\n","        Calcular accuracy después de cada iteración\n","        \"\"\"\n","        return np.mean(np.argmax(predicted, axis=1)==actual)\n","        \n","    def _calculate_loss(self, predicted, actual):\n","        \"\"\"\n","        Calculate cross-entropy loss after each iteration\n","        \"\"\"\n","        samples = len(actual)\n","\n","        correct_logprobs = -np.log(predicted[range(samples),actual])\n","        data_loss = np.sum(correct_logprobs)/samples\n","\n","        return data_loss\n","\n","    def train(self, X_train, y_train, epochs):\n","        \"\"\"\n","        Entrenar el modelo Stochastic Gradient Descent\n","        \"\"\"\n","        self.loss = []\n","        self.accuracy = []\n","\n","        self._init_weights(X_train)\n","\n","        for i in range(epochs):\n","            yhat = self._forwardprop(X_train)\n","            self.accuracy.append(self._get_accuracy(predicted=yhat, actual=y_train))\n","            self.loss.append(self._calculate_loss(predicted=yhat, actual=y_train))\n","\n","            self._backprop(predicted=yhat, actual=y_train)\n","\n","            self._update()\n","\n","            if i % 20 == 0:\n","                s = 'EPOCH: {}, ACCURACY: {}, LOSS: {}'.format(i, self.accuracy[-1], self.loss[-1])\n","                print(s)\n","\n","        return (self.accuracy, self.loss)"]},{"cell_type":"markdown","metadata":{},"source":["1."]},{"cell_type":"code","execution_count":73,"metadata":{},"outputs":[],"source":["red = RedNeuronal(learning_rate=0.01)\n","neuronas = [6,8,10,3]\n","for neurona in neuronas:\n","    capa = Capa(neurona)\n","    red.add(capa)\n","    \n","#red._compile(X)"]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[{"data":{"text/plain":["[]"]},"execution_count":74,"metadata":{},"output_type":"execute_result"}],"source":["red.arquitectura #es lo que nos pedían en el enunciado"]},{"cell_type":"markdown","metadata":{},"source":["2."]},{"cell_type":"code","execution_count":75,"metadata":{},"outputs":[{"data":{"text/plain":["<__main__.RedNeuronal at 0x1b95ffc76b0>"]},"execution_count":75,"metadata":{},"output_type":"execute_result"}],"source":["red._init_weights(X)"]},{"cell_type":"markdown","metadata":{},"source":["3."]},{"cell_type":"code","execution_count":76,"metadata":{},"outputs":[{"data":{"text/plain":["array([[1.3, 5.1, 0. , 0.7, 1.1]])"]},"execution_count":76,"metadata":{},"output_type":"execute_result"}],"source":["prueba = np.array([[1.3, 5.1, -2.2, 0.7, 1.1]])\n","capa = Capa(5)\n","capa.relu(prueba)"]},{"cell_type":"code","execution_count":77,"metadata":{},"outputs":[{"data":{"text/plain":["array([[2.12319074e-02, 9.49091411e-01, 6.41148049e-04, 1.16523179e-02,\n","        1.73832156e-02]])"]},"execution_count":77,"metadata":{},"output_type":"execute_result"}],"source":["prueba = np.array([[1.3, 5.1, -2.2, 0.7, 1.1]])\n","capa = Capa(5)\n","capa.softmax(prueba)"]},{"cell_type":"code","execution_count":78,"metadata":{},"outputs":[{"data":{"text/plain":["(150, 3)"]},"execution_count":78,"metadata":{},"output_type":"execute_result"}],"source":["red._forwardprop(X).shape"]},{"cell_type":"code","execution_count":79,"metadata":{},"outputs":[{"data":{"text/plain":["(150, 4)"]},"execution_count":79,"metadata":{},"output_type":"execute_result"}],"source":["X.shape"]},{"cell_type":"code","execution_count":80,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.16617107 0.81859653 0.0152324 ]\n","0\n"]}],"source":["print(red._forwardprop(X)[0])\n","print(y[0])"]},{"cell_type":"markdown","metadata":{},"source":["4. \n","Respuestas:\n","1. Nos devuelve una matriz de #instancias x #clases, en este caso, tenemos 3 clases, cada tipo de flor.\n","2. Para cada fila, es decir, cada instancia, tenemos la probabilidad de pertenecer a cada una de las clases.\n","3. Nos da los resultados: [0.16617107, 0.81859653, 0.0152324 ], lo que nos dice que el más probable versicolor. Sin embargo, el real es 0 (setosa). La razón por la cual da tan mal, es porque el modelo no está entrenado."]},{"cell_type":"markdown","metadata":{},"source":["5.\n","1. Para los negativos asigna 0 y para los positivos asigna 1. Pero en el código teníamos que a los positivos los dejaba como estaba, por eso había que completar con:\n","dZ[Z > 0] = 1 #a los positivos les asigna 1\n","2. La operación matemática son todas las derivadas necesarias.\n","3. En predicted le tenemos que pasar el resultado de _forwardprop(...) y en actual le pasamos y.\n","4. veamoslo:"]},{"cell_type":"code","execution_count":81,"metadata":{},"outputs":[],"source":["red._backprop(red._forwardprop(X), y)"]},{"cell_type":"code","execution_count":98,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(4, 6)\n","(1, 6)\n","(6, 8)\n","(1, 8)\n","(8, 10)\n","(1, 10)\n","(10, 3)\n","(1, 3)\n"]}],"source":["#como miro el shape de cada elemento del diccionario\n","for i in range(len(red.gradientes)):\n","    print(red.gradientes[i]['dW'].shape)\n","    print(red.gradientes[i]['db'].shape)\n","\n","#red.gradientes"]},{"cell_type":"markdown","metadata":{},"source":["6.\n","update: actualiza los pesos del modelo en base al gradiente y el learning rate, que es el paso.\n","\n","get_accuracy: calcula el accuracy \n","\n","calculate_loss: calcula la entropía cruzada "]},{"cell_type":"markdown","metadata":{},"source":["7.\n","1. Los valores que se imprimen son dada la epoca:\n","* el valor del accuracy para esa época\n","* el valor de la función de pérdida usando entropía cruzada para esa época\n","Vemos que desde la época 20 no cambia el accuracy y cambian muy pocos decimales de la función de costo (casi nada). "]},{"cell_type":"code","execution_count":100,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["EPOCH: 0, ACCURACY: 0.25333333333333335, LOSS: 2.537401260962661\n","EPOCH: 20, ACCURACY: 0.3333333333333333, LOSS: 1.0986147070059744\n","EPOCH: 40, ACCURACY: 0.3333333333333333, LOSS: 1.0986144044434354\n","EPOCH: 60, ACCURACY: 0.3333333333333333, LOSS: 1.0986141397473594\n","EPOCH: 80, ACCURACY: 0.3333333333333333, LOSS: 1.0986139081764237\n","EPOCH: 100, ACCURACY: 0.3333333333333333, LOSS: 1.0986137055833822\n","EPOCH: 120, ACCURACY: 0.3333333333333333, LOSS: 1.0986135283405558\n","EPOCH: 140, ACCURACY: 0.3333333333333333, LOSS: 1.0986133732746752\n","EPOCH: 160, ACCURACY: 0.3333333333333333, LOSS: 1.0986132376099178\n","EPOCH: 180, ACCURACY: 0.3333333333333333, LOSS: 1.0986131189180834\n"]},{"data":{"text/plain":["([0.25333333333333335,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333,\n","  0.3333333333333333],\n"," [2.537401260962661,\n","  1.0986150344427683,\n","  1.098615016152653,\n","  1.0986149979844226,\n","  1.0986149799372646,\n","  1.0986149620103711,\n","  1.0986149442029414,\n","  1.0986149265141778,\n","  1.0986149089432893,\n","  1.0986148914894902,\n","  1.0986148741519997,\n","  1.0986148569300418,\n","  1.0986148398228466,\n","  1.0986148228296486,\n","  1.0986148059496876,\n","  1.0986147891822096,\n","  1.0986147725264632,\n","  1.0986147559817039,\n","  1.098614739547192,\n","  1.0986147232221921,\n","  1.0986147070059744,\n","  1.0986146908978132,\n","  1.0986146748969885,\n","  1.098614659002784,\n","  1.0986146432144894,\n","  1.0986146275313984,\n","  1.0986146119528089,\n","  1.0986145964780254,\n","  1.0986145811063546,\n","  1.0986145658371103,\n","  1.0986145506696081,\n","  1.0986145356031713,\n","  1.098614520637125,\n","  1.0986145057708,\n","  1.0986144910035323,\n","  1.0986144763346597,\n","  1.098614461763528,\n","  1.098614447289485,\n","  1.0986144329118828,\n","  1.0986144186300797,\n","  1.0986144044434354,\n","  1.0986143903513177,\n","  1.0986143763530942,\n","  1.0986143624481406,\n","  1.0986143486358333,\n","  1.098614334915557,\n","  1.0986143212866963,\n","  1.0986143077486425,\n","  1.0986142943007897,\n","  1.0986142809425383,\n","  1.0986142676732886,\n","  1.0986142544924489,\n","  1.098614241399429,\n","  1.0986142283936442,\n","  1.098614215474512,\n","  1.098614202641456,\n","  1.0986141898939017,\n","  1.098614177231279,\n","  1.0986141646530223,\n","  1.0986141521585684,\n","  1.0986141397473594,\n","  1.0986141274188392,\n","  1.0986141151724582,\n","  1.0986141030076684,\n","  1.0986140909239253,\n","  1.0986140789206893,\n","  1.0986140669974231,\n","  1.0986140551535943,\n","  1.098614043388673,\n","  1.0986140317021333,\n","  1.0986140200934529,\n","  1.0986140085621128,\n","  1.0986139971075972,\n","  1.0986139857293942,\n","  1.0986139744269954,\n","  1.0986139631998946,\n","  1.0986139520475917,\n","  1.0986139409695859,\n","  1.0986139299653837,\n","  1.0986139190344921,\n","  1.0986139081764237,\n","  1.0986138973906916,\n","  1.0986138866768138,\n","  1.0986138760343127,\n","  1.0986138654627118,\n","  1.098613854961539,\n","  1.098613844530324,\n","  1.098613834168601,\n","  1.0986138238759064,\n","  1.0986138136517807,\n","  1.0986138034957673,\n","  1.0986137934074112,\n","  1.0986137833862617,\n","  1.0986137734318713,\n","  1.0986137635437945,\n","  1.09861375372159,\n","  1.0986137439648185,\n","  1.0986137342730438,\n","  1.0986137246458327,\n","  1.0986137150827546,\n","  1.0986137055833822,\n","  1.0986136961472914,\n","  1.0986136867740606,\n","  1.09861367746327,\n","  1.0986136682145047,\n","  1.0986136590273494,\n","  1.0986136499013959,\n","  1.0986136408362335,\n","  1.0986136318314599,\n","  1.0986136228866707,\n","  1.0986136140014668,\n","  1.0986136051754516,\n","  1.09861359640823,\n","  1.0986135876994099,\n","  1.0986135790486025,\n","  1.0986135704554214,\n","  1.0986135619194823,\n","  1.0986135534404042,\n","  1.0986135450178072,\n","  1.098613536651316,\n","  1.0986135283405558,\n","  1.0986135200851557,\n","  1.0986135118847462,\n","  1.0986135037389617,\n","  1.0986134956474378,\n","  1.0986134876098128,\n","  1.098613479625728,\n","  1.0986134716948257,\n","  1.0986134638167522,\n","  1.0986134559911547,\n","  1.0986134482176848,\n","  1.0986134404959942,\n","  1.0986134328257382,\n","  1.0986134252065736,\n","  1.0986134176381606,\n","  1.0986134101201603,\n","  1.0986134026522374,\n","  1.098613395234057,\n","  1.0986133878652902,\n","  1.098613380545605,\n","  1.0986133732746752,\n","  1.0986133660521769,\n","  1.0986133588777864,\n","  1.0986133517511834,\n","  1.0986133446720492,\n","  1.0986133376400675,\n","  1.0986133306549244,\n","  1.098613323716308,\n","  1.098613316823908,\n","  1.0986133099774165,\n","  1.0986133031765275,\n","  1.0986132964209374,\n","  1.0986132897103433,\n","  1.0986132830444464,\n","  1.0986132764229488,\n","  1.0986132698455553,\n","  1.0986132633119705,\n","  1.0986132568219034,\n","  1.0986132503750643,\n","  1.0986132439711642,\n","  1.0986132376099178,\n","  1.098613231291041,\n","  1.0986132250142506,\n","  1.0986132187792677,\n","  1.098613212585812,\n","  1.0986132064336076,\n","  1.0986132003223794,\n","  1.0986131942518549,\n","  1.098613188221763,\n","  1.0986131822318332,\n","  1.0986131762817986,\n","  1.0986131703713944,\n","  1.0986131645003547,\n","  1.0986131586684185,\n","  1.0986131528753247,\n","  1.0986131471208145,\n","  1.0986131414046314,\n","  1.0986131357265194,\n","  1.098613130086225,\n","  1.0986131244834962,\n","  1.0986131189180834,\n","  1.098613113389737,\n","  1.0986131078982102,\n","  1.0986131024432586,\n","  1.0986130970246366,\n","  1.0986130916421044,\n","  1.098613086295421,\n","  1.0986130809843466,\n","  1.0986130757086445,\n","  1.0986130704680792,\n","  1.098613065262416,\n","  1.098613060091423,\n","  1.0986130549548696,\n","  1.0986130498525246,\n","  1.0986130447841622,\n","  1.0986130397495546,\n","  1.0986130347484777,\n","  1.0986130297807075,\n","  1.0986130248460229,\n","  1.0986130199442028])"]},"execution_count":100,"metadata":{},"output_type":"execute_result"}],"source":["red_final = RedNeuronal(learning_rate=0.01)\n","neuronas = [6,8,10,3]\n","for neurona in neuronas:\n","    capa = Capa(neurona)\n","    red_final.add(capa)\n","\n","red_final.train(X, y, 200)"]},{"cell_type":"code","execution_count":106,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["plt.plot(range(0,200),red_final.accuracy)\n","plt.show()"]},{"cell_type":"code","execution_count":107,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["plt.plot(range(0,200),red_final.loss)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["Los items que se presentan a continuación tienen como objetivo explorar las clases que componen la red neuronal propuesta, comprender su arquitectura y funcionamiento.\n","\n","Nuevamente, lo ideal es no mirar todos los métodos hasta que llegue el momento de utilizarlos. \n","\n","1. Crear una Red Neuronal con 6 nodos en la primera capa, 8 en la segunda, 10 en la tercer y finalmente 3 en la última, utilizando los métodos `add()`, `_compile()` de la clase `RedNeuronal` y el constructor de la clase `Capa`.\n","  \n","    Imprimir la arquitectura del modelo y asegurarse de obtener:\n","\n","    ```\n","    [{'input_dim': 4, 'output_dim': 6, 'activation': 'relu'},\n","    {'input_dim': 6, 'output_dim': 8, 'activation': 'relu'},\n","    {'input_dim': 8, 'output_dim': 10, 'activation': 'relu'},\n","    {'input_dim': 10, 'output_dim': 3, 'activation': 'softmax'}]\n","    ```\n","\n","    Dibujar la red en papel.\n","\n","1. Inicializar los pesos de la red del punto anterior (`_init_weights(datos)`) y verificar que los pesos tienen dimensión correcta:\n","\n","    ```\n","    capa 0: w=(4, 6) - b=(1, 6)\n","    capa 1: w=(6, 8) - b=(1, 8)\n","    capa 2: w=(8, 10) - b=(1, 10)\n","    capa 3: w=(10, 3) - b=(1, 3)\n","    ```\n","\n","    Definir las matrices que se corresponden con las capas de manera que una pasada pueda ser interpretada como el producto de todas ellas. Recordar que en cada paso por cada capa estaremos computando por cada neurona de la capa siguiente:\n","\n","    $$Z = \\sum_{i=1}^{n} X_i \\times W_i + b$$\n","\n","1. Funciones de activación de una `Capa`:\n","\n","    1. Verificar que el funcionamiento de `ReLU` se corresponda con:\n","\n","        ```\n","        if input > 0:\n","            return input\n","        else:\n","            return 0\n","        ``` \n","\n","    1. Verificar que el funcionamiento de `softmax` se corresponda con:\n","\n","        $$\\sigma(Z)_i = \\frac{e^{z_i}}{\\sum_{i=1}^{n} e^{z_j}}$$\n","\n","    **Nota**: para probar estos dos métodos puede ser util construir un vector de la siguiente manera: `np.array([[1.3, 5.1, -2.2, 0.7, 1.1]])` que genera un vector de tamaño (1,5).\n","\n","1. Avancemos con `_forwardprop(datos)`, si corremos la red inicializada con los datos:\n","\n","    1. ¿Qué nos tipo de objeto nos devuelve este método?\n","\n","    1. ¿Qué quiere decir cada uno de los valores?\n","\n","    1. La primera fila, que se correspondería con la primera observación del dataset, ¿qué resultados nos da?¿qué es más probable: 'setosa', 'versicolor' o 'virginica'?¿qué valor es el real?¿por qué?\n","\n","1. Arrancamos a propagar para atrás lo aprendido en la primera pasada. Esto lo realizaremos con el método `_backprop`.\n","\n","    1. ¿Cómo es la derivada de la función de activación `ReLU`?¿Su código es correcto?\n","\n","    1. ¿Cuál es la operación matemática que hace la función `backward` de la clase `Capa` en el caso de tener como activación a `relu`?\n","\n","    1. El método `_backprop` toma 2 parámetros: `predicted` y `actual`. ¿qué debemos pasarle en dicho lugar?\n","\n","        Si la respuesta no fue: en `predicted` le pasamos el resultado de `_forwardprop(...)` y en `actual` le pasamos `y`.... volver a pensarlo. ;-)\n","\n","    1. Verificar que los `gradientes` y los `pesos` para cada una de las capas tienen el mismo tamaño.\n","\n","1. Preparemos por último las funciones necesarias para el entrenamiento. Describir brevemente qué hacen las funciones:\n","\n","    - `_get_accuracy`\n","    - `_calculate_loss`\n","    - `_update`\n","\n","1. Incluyamos finalmente la función `train` y entrenemos una red con la arquitectura propuesta en el punto 1 por 200 epocas.\n","\n","    1. ¿Qué valores se imprimen?¿Qué es posible interpretar de ellos?\n","\n","    1. Graficar el _accuracy_ y la _loss_ que arroja el entramiento en función de las _epochs_. ¿Qué se puede concluir? Probablemente la señal sea ruidosa, por lo que se recomienda hacer un suavizado por ventanas deslizantes.\n","\n","\n","Crédito: este ejercicio se base en la propuesta de Joe Sasson publicada en [Towards Data Science](https://towardsdatascience.com/coding-a-neural-network-from-scratch-in-numpy-31f04e4d605)."]},{"cell_type":"markdown","metadata":{},"source":["### Código completo\n"]},{"cell_type":"code","execution_count":390,"metadata":{},"outputs":[],"source":["class Capa:\n","    def __init__(self, neuronas):\n","        self.neuronas = neuronas\n","\n","    def forward(self, inputs, weights, bias, activation):\n","        \"\"\"\n","        Forward Propagation de la capa\n","        \"\"\"\n","        Z_curr = np.dot(inputs, weights.T) + bias\n","\n","        if activation == 'relu':\n","            A_curr = self.relu(inputs=Z_curr)\n","        elif activation == 'softmax':\n","            A_curr = self.softmax(inputs=Z_curr)\n","\n","        return A_curr, Z_curr\n","\n","    def relu(self, inputs):\n","        \"\"\"\n","        ReLU: función de activación\n","        \"\"\"\n","\n","        return np.maximum(0, inputs)\n","\n","    def softmax(self, inputs):\n","        \"\"\"\n","        Softmax: función de activación\n","        \"\"\"\n","        exp_scores = np.exp(inputs)\n","        probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n","        return probs\n","         \n","    def backward(self, dA_curr, W_curr, Z_curr, A_prev, activation):\n","        \"\"\"\n","        Backward Propagation de la capa\n","        \"\"\"\n","        if activation == 'softmax':\n","            dW = np.dot(A_prev.T, dA_curr)\n","            db = np.sum(dA_curr, axis=0, keepdims=True)\n","            dA = np.dot(dA_curr, W_curr) \n","        else:\n","            dZ = self.relu_derivative(dA_curr, Z_curr)\n","            dW = np.dot(A_prev.T, dZ)\n","            db = np.sum(dZ, axis=0, keepdims=True)\n","            dA = np.dot(dZ, W_curr)\n","            \n","        return dA, dW, db\n","\n","    def relu_derivative(self, dA, Z):\n","        \"\"\"\n","        ReLU: gradiente de ReLU\n","        \"\"\"\n","        dZ = np.array(dA, copy = True)\n","        dZ[Z <= 0] = 0\n","        return dZ\n","    "]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["class RedNeuronal:\n","    def __init__(self, learning_rate=0.01):\n","        self.red = [] ## capas\n","        self.arquitectura = [] ## mapeo de entradas -> salidas\n","        self.pesos = [] ## W, b\n","        self.memoria = [] ## Z, A\n","        self.gradientes = [] ## dW, db\n","        self.lr = learning_rate\n","        \n","    def add(self, capa):\n","        \"\"\"\n","        Agregar capa a la red\n","        \"\"\"\n","        self.red.append(capa)\n","            \n","    def _compile(self, data):\n","        \"\"\"\n","        Inicializar la arquitectura\n","        \"\"\"\n","        for idx, _ in enumerate(self.red):\n","            if idx == 0:\n","                self.arquitectura.append({'input_dim': data.shape[1], \n","                                        'output_dim': self.red[idx].neuronas,\n","                                        'activation':'relu'})\n","            elif idx > 0 and idx < len(self.red)-1:\n","                self.arquitectura.append({'input_dim': self.red[idx-1].neuronas, \n","                                        'output_dim': self.red[idx].neuronas,\n","                                        'activation':'relu'})\n","            else:\n","                self.arquitectura.append({'input_dim': self.red[idx-1].neuronas, \n","                                        'output_dim': self.red[idx].neuronas,\n","                                        'activation':'softmax'})\n","        return self\n","\n","    def _init_weights(self, data):\n","        \"\"\"\n","        Inicializar arquitectura y los pesos\n","        \"\"\"\n","        self._compile(data)\n","\n","        np.random.seed(99)\n","\n","        for i in range(len(self.arquitectura)):\n","            self.pesos.append({\n","                'W':np.random.uniform(low=-1, high=1, \n","                        size=(self.arquitectura[i]['input_dim'],\n","                            self.arquitectura[i]['output_dim']\n","                            )),\n","                'b':np.zeros((1, self.arquitectura[i]['output_dim']))})\n","\n","        return self\n","    \n","    def _forwardprop(self, data):\n","        \"\"\"\n","        Pasada forward completa por la red\n","        \"\"\"\n","        A_curr = data\n","\n","        for i in range(len(self.pesos)):\n","            A_prev = A_curr\n","            A_curr, Z_curr = self.red[i].forward(inputs=A_prev, \n","                                                    weights=self.pesos[i]['W'].T, \n","                                                    bias=self.pesos[i]['b'], \n","                                                    activation=self.arquitectura[i]['activation'])\n","\n","            self.memoria.append({'inputs':A_prev, 'Z':Z_curr})\n","\n","        return A_curr\n","    \n","    def _backprop(self, predicted, actual):\n","        \"\"\"\n","        Pasada backward completa por la red\n","        \"\"\"\n","        num_samples = len(actual)\n","\n","        ## compute the gradient on predictions\n","        dscores = predicted\n","        dscores[range(num_samples),actual] -= 1\n","        dscores /= num_samples\n","\n","        dA_prev = dscores\n","\n","        for idx, layer in reversed(list(enumerate(self.red))):\n","            dA_curr = dA_prev\n","\n","            A_prev = self.memoria[idx]['inputs']\n","            Z_curr = self.memoria[idx]['Z']\n","            W_curr = self.pesos[idx]['W']\n","\n","            activation = self.arquitectura[idx]['activation']\n","\n","            dA_prev, dW_curr, db_curr = layer.backward(dA_curr, W_curr.T, Z_curr, A_prev, activation)\n","\n","            self.gradientes.append({'dW':dW_curr, 'db':db_curr})\n","\n","        self.gradientes = list(reversed(self.gradientes))  # Reverse the gradients list\n","\n","    def _update(self):\n","        \"\"\"\n","        Actualizar el modelo --> lr * gradiente\n","        \"\"\"\n","        lr = self.lr\n","        for idx, layer in enumerate(self.red):\n","            self.pesos[idx]['W'] -= lr * self.gradientes[idx]['dW']\n","            self.pesos[idx]['b'] -= lr * self.gradientes[idx]['db']\n","\n","    def _get_accuracy(self, predicted, actual):\n","        \"\"\"\n","        Calcular accuracy después de cada iteración\n","        \"\"\"\n","        return np.mean(np.argmax(predicted, axis=1)==actual)\n","        \n","    def _calculate_loss(self, predicted, actual):\n","        \"\"\"\n","        Calculate cross-entropy loss after each iteration\n","        \"\"\"\n","        samples = len(actual)\n","\n","        correct_logprobs = -np.log(predicted[range(samples),actual])\n","        data_loss = np.sum(correct_logprobs)/samples\n","\n","        return data_loss\n","\n","    def train(self, X_train, y_train, epochs):\n","        \"\"\"\n","        Entrenar el modelo Stochastic Gradient Descent\n","        \"\"\"\n","        self.loss = []\n","        self.accuracy = []\n","\n","        self._init_weights(X_train)\n","\n","        for i in range(epochs):\n","            yhat = self._forwardprop(X_train)\n","            self.accuracy.append(self._get_accuracy(predicted=yhat, actual=y_train))\n","            self.loss.append(self._calculate_loss(predicted=yhat, actual=y_train))\n","\n","            self._backprop(predicted=yhat, actual=y_train)\n","\n","            self._update()\n","\n","            if i % 20 == 0:\n","                s = 'EPOCH: {}, ACCURACY: {}, LOSS: {}'.format(i, self.accuracy[-1], self.loss[-1])\n","                print(s)\n","\n","        return (self.accuracy, self.loss)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from graphviz import Digraph, Graph\n","\n","def dibujar_red(red):\n","    dot = Graph()\n","    dot.attr(rankdir=\"LR\")\n","    dot.attr(splines=\"false\")\n","    dot.attr(nodesep=\"0.05\")\n","    \n","    for idx,capa in enumerate(red.arquitectura):\n","        with dot.subgraph(name=f'cluster_{idx}') as c:\n","            c.attr(rank=\"same\")\n","            for i in range(capa['input_dim']+1):\n","                c.node(nombre_nodo(idx, i), label=etiqueta_nodo(idx,i))\n","\n","            c.attr(color='white')\n","            \n","            label_extra = \"Entrada\" if idx == 0 else \"Oculta\\n(ReLU)\"\n","        \n","            c.attr(label=f'capa {idx+1}\\n{label_extra}')\n","\n","    with dot.subgraph(name=f'cluster_{idx+1}') as c:\n","            c.attr(rank=\"same\")\n","            for i in range(capa['output_dim']):\n","                c.node(nombre_nodo(idx+1, i), label=etiqueta_nodo(idx+1,i, True))\n","\n","            c.attr(color='white')\n","            \n","            label_extra = \"Salida\\n(SoftMax)\"\n","        \n","            c.attr(label=f'capa {idx+1}\\n{label_extra}')\n","\n","    for idx, capa in enumerate(red.arquitectura):\n","        for in_idx in range(capa[\"input_dim\"]+1):\n","            for out_idx in range(capa[\"output_dim\"]):\n","                to_node = (idx+1, out_idx+1) if idx!=len(red.arquitectura)-1 else (idx+1, out_idx)\n","                dot.edge(nombre_nodo(idx, in_idx), \n","                         nombre_nodo(*to_node))\n","\n","    return dot\n","\n","def nombre_nodo(capa, indice):\n","    res = f\"c_{capa}_{indice}\"\n","    return res\n","\n","def etiqueta_nodo(capa, indice, es_final=False):\n","    if indice==0 and not es_final:\n","        return \"1\"\n","    l = \"a\" if capa!=0 else \"x\"\n","    l = l if not es_final else \"y\"\n","    \n","    if l==\"x\" or l==\"y\":    \n","        return f\"<{l}<sub>{indice}</sub>>\"\n","    else:\n","        return f\"<{l}<sub>{indice}</sub><sup>({capa})</sup>>\"\n","\n","# model = RedNeuronal()\n","# model.add(...)\n","# model._compile(...datos...)\n","\n","dibujar_red(model)"]}],"metadata":{"celltoolbar":"Tags","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":2}
