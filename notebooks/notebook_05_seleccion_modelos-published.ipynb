{"cells":[{"cell_type":"markdown","metadata":{},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/aprendizaje-automatico-dc-uba-ar/material/blob/main/notebooks/notebook_05_seleccion_modelos-published.ipynb)\n","\n","# Selección de modelos"]},{"cell_type":"markdown","metadata":{},"source":["## Cross validation \n","\n","Hasta ahora sólo habíamos visto (ver en el [notebook 03](https://github.com/aprendizaje-automatico-dc-uba-ar/material/blob/main/notebooks/notebook_03_arboles_de_decision_sklearn-published.ipynb)) que ibamos a dividir los datos en train y test.\n","\n","\n","En esta semana vimos la opción de hacer validación cruzada. En esta oportunidad lo que haremos sera realizar una exploración de hiperparámetros para árboles incorporando conceptos de la clase de esta semana.\n","Vamos a experimentar usando k-fold (con k=10) para explorar distintos valores de configuración de `DecisionTreeClassifier` para seleccionar el hiperparámetro que nos parezca el mejor. \n","Ensayaremos áltura máxima con valores `[None, 1, 2, 3, 5, 8, 13, 21]`. \n","\n","Nos interesará:\n","- controlar el tiempo de entrenamiento\n","- generar alguna métrica que elijamos para seleccionar la áltura máxima\n","\n","Con la mejor configuración obtenida entrenar un clasificador con todos los datos de desarrollo.\n","    \n","Evaluar el comportamiento con el set de evaluación\n","    \n","\n"]},{"cell_type":"markdown","metadata":{},"source":["Primero separaremos nuestro data set entre **desarrollo** y **evaluación** en un 10%. Para esto podemos usar `train_test_split`"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Longitud original:\", len(y))\n","print(\"Longitud del set de desarrollo:\", len(y_dev))\n","print(\"Longitud del set de evaluación:\", len(y_eval))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def train_tree(X_tr: np.ndarray, y_tr: np.ndarray, tree_params={}) -> DecisionTreeClassifier:\n","    arbol = DecisionTreeClassifier(**tree_params) #crea el arbol con ciertos hiperparametros que le pasas: la altura maxima \n","    arbol.fit(X_tr, y_tr)\n","\n","    return arbol\n","\n","def tree_predict(ab: DecisionTreeClassifier, X_test: np.ndarray) -> np.ndarray:\n","    predictions = ab.predict(X_test) #le pasas el arbol ya entrenado y te devuelve las predicciones del test\n","    return predictions"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def accuracy(y_predicted: np.ndarray, y_real: np.ndarray) -> float:\n","    TP_TN = sum([y_i == y_j for (y_i, y_j) in zip(y_predicted, y_real)]) \n","    P_N = len(y_real)\n","    return TP_TN /P_N\n","\n","def precision_recall(y_predicted: np.ndarray, y_real: np.ndarray) -> np.ndarray:\n","    TP = sum([y_i == 1 and y_j == 1 for (y_i, y_j) in zip(y_predicted, y_real)])\n","    FP = sum([y_i == 1 and y_j == 0 for (y_i, y_j) in zip(y_predicted, y_real)])\n","    FN = sum([y_i == 0 and y_j == 1 for (y_i, y_j) in zip(y_predicted, y_real)])\n","    precision = TP / (TP + FP)\n","    recall = TP / (TP + FN)\n","    return precision, recall\n","\n","def f_score(y_predicted: np.ndarray, y_real: np.ndarray, beta = 0.5) -> float:\n","    presicion, recall = precision_recall(y_predicted, y_real)\n","    f_score = (1 + beta**2) * (presicion * recall) / ((beta**2) * presicion + recall)\n","    return f_score\n","\n","def metrica_seleccionada(y_predicted: np.ndarray, y_real: np.ndarray) -> float:\n","    return accuracy(y_predicted, y_real)"]},{"cell_type":"markdown","metadata":{},"source":["Realización del experimento.\n","\n","Nota: se inicializa con una semilla para poder reproducir el resultado."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results = []\n","\n","np.random.seed(44)\n","for h_max in [None, 1, 2, 3, 5, 8, 13, 21]:\n","    kf = KFold(n_splits=10) #voy a usar 10 folds\n","    y_pred = np.empty(y_dev.shape)\n","    y_pred.fill(np.nan)\n","    \n","    # generamos para cada fold una predicción\n","    for train_index, test_index in kf.split(X_dev): \n","        #en train_index estan los indices de los datos que estan en los 9 folds que pertenecen a training\n","        #en test_index estan los indices de los datos que estan en el unico fold que es el test\n","        \n","        #saco el fold que no uso para entrenar\n","        kf_X_train, kf_X_test = X_dev[train_index], X_dev[test_index]\n","        kf_y_train, kf_y_test = y_dev[train_index], y_dev[test_index]\n","\n","        current_tree = train_tree(kf_X_train, kf_y_train,\n","                                    tree_params={\"max_depth\":h_max})\n","        predictions = tree_predict(current_tree, kf_X_test)\n","        y_pred[test_index] = predictions #quedan algunos vacios (con NAs) en cada iteracion pero finalmente se llena todo\n","        \n","    current_score = metrica_seleccionada(y_pred, y_dev) #mido que tan bien me fue con las predicciones\n","    \n","    results.append((h_max,current_score)) #para cada altura se guarda la performance\n","    \n","\n","# Ordenamos los resultados (puede ser que convenga del derecho o del reves) por score de mayor a menor\n","r = sorted(results, key=lambda x: x[1], reverse=True)\n","\n","print(\"Órden obtenido según la métrica elegida\")\n","for idx, (h, sc) in enumerate(r):\n","    print(f\"\\t{idx+1}- h_max={h} con {sc:.3f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# elegimos la altura 1 porque es el que más F-score tuvo\n","h_max = r[0][0] \n","selection_score = r[0][1] \n","print(h_max)\n","print(selection_score)"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Construimos nuestro clasificador con parámetro 'max_depth'=1.\n","Para seleccionarlo el score que habíamos obtenido era 0.881\n"]}],"source":["print(f\"Construimos nuestro clasificador con parámetro 'max_depth'={h_max}.\"\n","     + f\"\\nPara seleccionarlo el score que habíamos obtenido era {selection_score:.3f}\")\n","\n","best_tree = train_tree(X_dev, y_dev,\n","                            tree_params={\"max_depth\":h_max})\n"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["El F-score del árbol seleccionado es 0.904\n"]}],"source":["y_pred = tree_predict(best_tree, X_dev)\n","best_tree_score = metrica_seleccionada(y_pred, y_dev)\n","print(f\"El F-score del árbol seleccionado es {best_tree_score:.3f}\")"]},{"cell_type":"markdown","metadata":{},"source":["¿Qué nos están diciendo estos dos scores?¿Para qué nos sirven?"]},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Con el árbol entrenado con el parámetro seleccionado tenemos en eval un score de 0.733\n"]}],"source":["y_pred_eval = tree_predict(best_tree, X_eval)       \n","best_tree_score_eval = metrica_seleccionada(y_pred_eval, y_eval)\n","\n","print(f\"Con el árbol entrenado con el parámetro seleccionado tenemos en eval un score de {best_tree_score_eval:.3f}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Opcionales\n","\n","1. Simular qué hubiese ocurrido si hubieramos elegido un K distinto. ¿La diferencia entre el score en *dev* y el score en *eval* cambia significativamente?\n","2. Repetir el mismo ejercicio de elegir la mejor combinación de parametros pero esta vez establecer una grilla donde se exploren al menos dos hiperparámetros que no sean la altura máxima. Revisar la documentación de `DecisionTreeClassifier`, por ejemplo pueden elegir la **medida de impureza** y el **mínimo de muestas necesario para realizar un split**. Definir los rangos necesarios para explorar más de un valor de cada hiperparámetro considerado. ¿Este modelo fue mejor que el obtenido en el punto anterior?\n","\n","**Importante**: en este punto nos tomamos la licencia de usar nuevamente el conjunto de evaluación. El re-uso de el conjunto de evaluación sólo lo permitimos en este caso por motivos pedagócios. Pero **NO DEBE** suceder en la práctica.\n","\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":2}
